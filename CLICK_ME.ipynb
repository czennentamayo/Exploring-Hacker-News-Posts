{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will be exploring the popular website [Hacker News](https://news.ycombinator.com/) by start up incubator [Y Combinator](https://www.ycombinator.com/). Users of the site submit stories known as \"posts\" which gets voted and commented upon by the its community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study, we will have special interest on posts which has titles starting with either `Ask HN` or `Show HN`. `Ask HN` posts asks the Hacker News Community as specific question, while `Show HN` posts shows generally something of interest. The goal of our study are to answer these questions:\n",
    "\n",
    "- On average, does `Ask HN` receive more comments than `Show HN`?\n",
    "- What specific time should a post be created to have a higher chance of getting comments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Our Data Set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we will be using can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). Our data set was updated last September of 2016 and has approximately 20,000 rows. Below are the description of the columns:\n",
    "\n",
    "- `id`: The unique identifier from Hacker News for the post\n",
    "- `title`: The title of the post\n",
    "- `url`: The URL that the posts links to, if the post has a URL\n",
    "- `num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments`: The number of comments that were made on the post\n",
    "- `author`: The username of the person who submitted the post\n",
    "- `created_at`: The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data (dataset, begin, end, show_len=True):\n",
    "    dataset_slice = dataset[begin:end]\n",
    "    for row in dataset_slice:\n",
    "        print (row , \"\\n\")\n",
    "    \n",
    "    #When show_len is True displays the total number of rows in our data set\n",
    "    if show_len == True:\n",
    "        data_set_len = len(dataset)\n",
    "        data_set_len = \"Length of data set is: {:,}\".format(data_set_len)\n",
    "        print (data_set_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function above `explore_data` will be used throughout our study. It will display a specified amount of rows in our data set and tell us how many rows there are in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'] \n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'] \n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'] \n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'] \n",
      "\n",
      "Length of data set is: 20,101\n"
     ]
    }
   ],
   "source": [
    "#Opens our data set and saves it into a variable named hn\n",
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "explore_data(hn, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our code above, we opened and read our data set which was in `hacker_nws.csv` and saved its contents in a variable called `hn`. We also displayed its first 5 rows (The first row displays our data set's headers) and now know that it has exactly 20,101 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing the Header Row:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'] \n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'] \n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'] \n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'] \n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12'] \n",
      "\n",
      "Length of data set is: 20,100\n"
     ]
    }
   ],
   "source": [
    "#Extracts our data set headers and put in the headers variable\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "explore_data(hn, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code above removes the header row from our data set and saves it in a variable named `headers`. We do this to make sure that our data when processed does not confuse the headers as a \"post\".\n",
    "\n",
    "We then displayed the first 5 rows to make sure that the headers were indeed removed, and verified that the length of our data set is now 20,100 which was previously 20,101."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Ask HN and Show HN Posts:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    \n",
    "    #Checks if the title of the post begins with \"ask hn\"\n",
    "    if title.startswith('ask hn') == True:\n",
    "        ask_posts.append(row)\n",
    "        \n",
    "    #Checks if the title of the post begins with \"show hn\"\n",
    "    elif title.startswith('show hn') == True:\n",
    "        show_posts.append(row)\n",
    "        \n",
    "    else:\n",
    "        other_posts.append(row)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code above extracted from our data set \"posts\" that starts with either `Ask HN` or `Show HN` and placed them in lists named `ask_posts` and `show_posts` respectively. We will also placed \"posts\" that does not belong into either category in a list called `other_posts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ask HN posts: 1,744\n",
      "Number of Show HN posts: 1,162\n",
      "Number of Other posts: 17,194\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of Ask HN posts: {:,}\".format(len(ask_posts)))\n",
    "print (\"Number of Show HN posts: {:,}\".format(len(show_posts)))\n",
    "print (\"Number of Other posts: {:,}\".format(len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code above shows that our data set has 1,744 `Ask HN` posts, 1,162 `Show HN` posts, and 17,194 `Other` posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating the Average Number of Comments for Ask HN and Show HN Posts:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_no_comments (dataset):\n",
    "    total_no_of_comments = 0\n",
    "    for row in dataset:\n",
    "        num_comments = int(row[4])\n",
    "        \n",
    "        #Adds the number of comments\n",
    "        total_no_of_comments += num_comments \n",
    "        \n",
    "    #Divides total number of comments to number of row\n",
    "    avg_no_comments = total_no_of_comments / len(dataset)\n",
    "    return avg_no_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function `get_avg_no_comments` will be used to get the average number of comments on our newly cleaned data sets. It does this by adding the total number of comments each post has and assign it to our variable `total_no_of_comments`. We then divide `total_no_of_comments` with the number of rows in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of comments of Ask HN posts: 14.04\n",
      "Average number of comments of Show HN posts: 10.32\n"
     ]
    }
   ],
   "source": [
    "#Displays the average number of comments for Ask HN posts\n",
    "avg_ask_comments = get_avg_no_comments(ask_posts)\n",
    "print (\"Average number of comments of Ask HN posts:\", \"{:.2f}\".format(avg_ask_comments))\n",
    "\n",
    "#Displays the average number of comments for Show HN posts\n",
    "avg_show_comments = get_avg_no_comments(show_posts)\n",
    "print (\"Average number of comments of Show HN posts:\", \"{:.2f}\".format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code above shoes that the average number of comments that `Ask HN` posts receives is 14.04, and `Show HN` posts has an average of 10.32. Our findings dictate that `Ask HN` posts on average receive more comments than `Show HN` posts. Since `Ask HN` posts are more likely to receive comments, we'll focus our remaning analysis just on these posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the Amount of Asks Posts and Comments by Hours Created:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our data analysis is to find out if `Ask HN` posts that are created at a certain time are more likely to attract comments. We will do this using these 2 steps:\n",
    "\n",
    "1. Calculate the amount of `Ask HN` posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list =[]\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = row[4]\n",
    "    result_list.append([created_at , num_comments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a new data set `result_list`. It contains the values of our `created_at` and `num_comments` columns of our `ask_posts` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "#Loops through our result_list data set\n",
    "for row in result_list:\n",
    "    comments = int(row[1])\n",
    "    hour = dt.datetime.strptime(row[0] , \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt.datetime.strftime(hour, \"%H\")\n",
    "    \n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above we looped through our `result_list` and created 2 new dictionaries. These dictionaries are:\n",
    "- `counts_by_hour`: contains the total number of `Ask HN` posts created at a specific.\n",
    "- `comments_by_hour`: contains the total number of comments created on `Ask HN` posts at a specific hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating the Average Number of Comments for Ask HN Posts by Hour:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "#Divides comments_by_hour by counts_by_hour to get the average number of comments per hour\n",
    "for hour in counts_by_hour:\n",
    "    avg_comment_hour = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour , avg_comment_hour])\n",
    "\n",
    "print (avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our code above we divided the values on our `comments_by_hour` dictionary with the values on our `counts_by_hour` dictionary to get the average number of comments per hour. We then stored our average values in our new data set `avg_by_hour`. We then displayed these values, but unfortunately it is hard to read due to its current format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting and Formatting Average Number of Comments Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments:\n",
      "15:00 - 38.59\n",
      "02:00 - 23.81\n",
      "20:00 - 21.52\n",
      "16:00 - 16.80\n",
      "21:00 - 16.01\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1] , row[0]])\n",
    "\n",
    "#Sorts our data set fron greatest to least comments per hour\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print (\"Top 5 Hours for Ask Posts Comments:\")\n",
    "\n",
    "#Formats our time to HH:MM and limits the average number of comments to 2 decimal places\n",
    "for row in sorted_swap[:5]:\n",
    "    time = dt.datetime.strptime(row[1], \"%H\")\n",
    "    time = dt.datetime.strftime(time, \"%H:%M\")\n",
    "    \n",
    "    avg_comments = \"{:.2f}\".format(row[0])\n",
    "    \n",
    "    print (time , \"-\" , avg_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code above sorted our data from greatest to least and displayed only the top 5 results. It also formatted the average number of comments per hour to a maximum of 2 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a post to have a higher chance of getting more comments it should be an `Ask HN` type of post and be posted around `15:00`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
